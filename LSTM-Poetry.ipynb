{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zh/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据, 生成汉字列表\n",
    "\n",
    "with open('poetry.txt') as f:\n",
    "    raw_text = f.read()\n",
    "lines = raw_text.split(\"\\n\")[:-1]\n",
    "poem_text = [i.split(':')[1] for i in lines]\n",
    "char_list = [re.findall('[\\x80-\\xff]{3}|[\\w\\W]', s) for s in poem_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217689, 4619, 4619)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 汉字 <-> 数字 映射\n",
    "\n",
    "all_words = []\n",
    "for i in char_list:\n",
    "    all_words.extend(i)\n",
    "word_dataframe = pd.DataFrame(pd.Series(all_words).value_counts())\n",
    "word_dataframe['id'] = list(range(1,len(word_dataframe)+1))\n",
    "\n",
    "word_index_dict = word_dataframe['id'].to_dict()\n",
    "index_dict = {}\n",
    "for k in word_index_dict:\n",
    "    index_dict.update({word_index_dict[k]:k})\n",
    "    \n",
    "len(all_words), len(word_dataframe), len(index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217687"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成训练数据, x 为 前两个汉字, y 为 接下来的汉字 \n",
    "# 如: 明月几时有 会被整理成下面三条数据\n",
    "# 明月 -> 几  月几 -> 时  几时 -> 有\n",
    "\n",
    "seq_len = 2\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(all_words) - seq_len, 1):\n",
    "    seq_in = all_words[i : i + seq_len]\n",
    "    seq_out = all_words[i + seq_len]\n",
    "    dataX.append([word_index_dict[x] for x in seq_in])\n",
    "    dataY.append(word_index_dict[seq_out])\n",
    "\n",
    "len(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((217687, 2), (217687, 4620))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(dataX)\n",
    "y = np_utils.to_categorical(np.array(dataY))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 512)         2364928   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4620)              2370060   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4620)              0         \n",
      "=================================================================\n",
      "Total params: 6,834,188\n",
      "Trainable params: 6,834,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Embedding 层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]\n",
    "# Embedding 层只能作为模型的第一层\n",
    "# input_dim：大或等于0的整数，字典长度\n",
    "# output_dim：大于0的整数，代表全连接嵌入的维度\n",
    "model.add(Embedding(len(word_dataframe), 512))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(512))\n",
    "\n",
    "# Dropout 防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output 为 y 的维度\n",
    "model.add(Dense(y.shape[1]))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "217687/217687 [==============================] - 47s - loss: 6.5194    \n",
      "Epoch 2/40\n",
      "217687/217687 [==============================] - 43s - loss: 6.0894    \n",
      "Epoch 3/40\n",
      "217687/217687 [==============================] - 44s - loss: 5.7482    \n",
      "Epoch 4/40\n",
      "217687/217687 [==============================] - 44s - loss: 5.4671    \n",
      "Epoch 5/40\n",
      "217687/217687 [==============================] - 44s - loss: 5.2141    \n",
      "Epoch 6/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.9809    \n",
      "Epoch 7/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.7727    \n",
      "Epoch 8/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.5822    \n",
      "Epoch 9/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.4151    \n",
      "Epoch 10/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.2630    \n",
      "Epoch 11/40\n",
      "217687/217687 [==============================] - 44s - loss: 4.1322    \n",
      "Epoch 12/40\n",
      "217687/217687 [==============================] - 43s - loss: 4.0099    \n",
      "Epoch 13/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.9117    \n",
      "Epoch 14/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.8129    \n",
      "Epoch 15/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.7193    \n",
      "Epoch 16/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.6510    \n",
      "Epoch 17/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.5849    \n",
      "Epoch 18/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.5212    \n",
      "Epoch 19/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.4631    \n",
      "Epoch 20/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.4117    \n",
      "Epoch 21/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.3675    \n",
      "Epoch 22/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.3214    \n",
      "Epoch 23/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.2818    \n",
      "Epoch 24/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.2532    \n",
      "Epoch 25/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.2178    \n",
      "Epoch 26/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.1881    \n",
      "Epoch 27/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.1576    \n",
      "Epoch 28/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.1314    \n",
      "Epoch 29/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.1077    \n",
      "Epoch 30/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.0814    \n",
      "Epoch 31/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.0635    \n",
      "Epoch 32/40\n",
      "217687/217687 [==============================] - 44s - loss: 3.0480    \n",
      "Epoch 33/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.0274    \n",
      "Epoch 34/40\n",
      "217687/217687 [==============================] - 43s - loss: 3.0054    \n",
      "Epoch 35/40\n",
      "217687/217687 [==============================] - 44s - loss: 2.9919    \n",
      "Epoch 36/40\n",
      "217687/217687 [==============================] - 43s - loss: 2.9718    \n",
      "Epoch 37/40\n",
      "217687/217687 [==============================] - 44s - loss: 2.9629    \n",
      "Epoch 38/40\n",
      "217687/217687 [==============================] - 44s - loss: 2.9430    \n",
      "Epoch 39/40\n",
      "217687/217687 [==============================] - 44s - loss: 2.9346    \n",
      "Epoch 40/40\n",
      "217687/217687 [==============================] - 44s - loss: 2.9202    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3174ed3250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "model.fit(X, y, batch_size=64, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0341976e-15, 2.1907965e-02, 1.1279847e-01, ..., 1.7754996e-10,\n",
       "        1.7678926e-14, 1.0797626e-09],\n",
       "       [3.9345502e-12, 1.9920176e-01, 2.0544907e-02, ..., 1.1154208e-08,\n",
       "        1.1879822e-12, 1.6002797e-08]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predict_array(seed_text):\n",
    "    chars = re.findall('[\\x80-\\xff]{3}|[\\w\\W]', seed_text)\n",
    "    x = np.array([word_index_dict[k] for k in chars])\n",
    "    proba = model.predict(x, verbose=0)\n",
    "    return proba\n",
    "\n",
    "get_predict_array(\"明月\")\n",
    "\n",
    "# 可以看到预测出来的结果是两个列表, 下一个字是第二个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_poetry(model, seed_text, rows=4, cols=5):\n",
    "    '''\n",
    "    生成诗词的函数\n",
    "    输入: 两个汉字, 行数, 每行的字数 (默认为五言绝句)\n",
    "    '''\n",
    "    total_cols = cols + 1  # 加上标点符号\n",
    "    chars = re.findall('[\\x80-\\xff]{3}|[\\w\\W]', seed_text)\n",
    "    if len(chars) != seq_len: # seq_len = 2\n",
    "        return \"\"\n",
    "    arr = [word_index_dict[k] for k in chars]\n",
    "    for i in range(seq_len, rows * total_cols):\n",
    "        if (i+1) % total_cols == 0:  # 逗号或句号\n",
    "            if (i+1) / total_cols == 2 or (i+1) / total_cols == 4:  # 句号的情况\n",
    "                arr.append(2)  # 句号在字典中的映射为 2\n",
    "            else:\n",
    "                arr.append(1)  # 逗号在字典中的映射为 1\n",
    "        else:\n",
    "            proba = model.predict(np.array(arr[-seq_len:]), verbose=0)\n",
    "            predicted = np.argsort(proba[1])[-5:]\n",
    "            index = random.randint(0,len(predicted)-1)  # 在前五个可能结果里随机取, 避免每次都是同样的结果\n",
    "            new_char = predicted[index]\n",
    "            while new_char == 1 or new_char == 2:  # 如果是逗号或句号, 应该重新换一个\n",
    "                index = random.randint(0,len(predicted)-1)\n",
    "                new_char = predicted[index]\n",
    "            arr.append(new_char)\n",
    "    poem = [index_dict[i] for i in arr]\n",
    "    return \"\".join(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明月明月上，今已见天涯。长信多异迹，不见月明德。\n",
      "悠然长城头一朝，不见山下流水曲。不得意切玉帛事，今在何处不可见。\n",
      "长河边草生得不，今在长安得不可。玉树乌号边草绿，万国恩光辉照海。\n"
     ]
    }
   ],
   "source": [
    "print(gen_poetry(model, '明月'))\n",
    "print(gen_poetry(model, '悠然', rows=4, cols=7))\n",
    "print(gen_poetry(model, '长河', rows=4, cols=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(filepath='lstm_poetry.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 试下 GRU\n",
    "\n",
    "gru = Sequential()\n",
    "gru.add(Embedding(len(word_dataframe), 512))\n",
    "gru.add(GRU(512))\n",
    "# gru.add(Dropout(0.5))\n",
    "gru.add(Dense(y.shape[1]))\n",
    "gru.add(Activation('softmax'))\n",
    "gru.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 512)         2364928   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 512)               1574400   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4620)              2370060   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4620)              0         \n",
      "=================================================================\n",
      "Total params: 6,309,388\n",
      "Trainable params: 6,309,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "217687/217687 [==============================] - 39s - loss: 6.3603    \n",
      "Epoch 2/40\n",
      "217687/217687 [==============================] - 39s - loss: 5.6961    \n",
      "Epoch 3/40\n",
      "217687/217687 [==============================] - 39s - loss: 5.1456    \n",
      "Epoch 4/40\n",
      "217687/217687 [==============================] - 39s - loss: 4.6007    \n",
      "Epoch 5/40\n",
      "217687/217687 [==============================] - 39s - loss: 4.1190    \n",
      "Epoch 6/40\n",
      "217687/217687 [==============================] - 39s - loss: 3.7241    \n",
      "Epoch 7/40\n",
      "217687/217687 [==============================] - 39s - loss: 3.4112    \n",
      "Epoch 8/40\n",
      "217687/217687 [==============================] - 39s - loss: 3.1593    \n",
      "Epoch 9/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.9692    \n",
      "Epoch 10/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.8208    \n",
      "Epoch 11/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.7050    \n",
      "Epoch 12/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.6151    \n",
      "Epoch 13/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.5418    \n",
      "Epoch 14/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.4889    \n",
      "Epoch 15/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.4401    \n",
      "Epoch 16/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.3996    \n",
      "Epoch 17/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.3698    \n",
      "Epoch 18/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.3407    \n",
      "Epoch 19/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.3145    \n",
      "Epoch 20/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2942    \n",
      "Epoch 21/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2749    \n",
      "Epoch 22/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2557    \n",
      "Epoch 23/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2390    \n",
      "Epoch 24/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2237    \n",
      "Epoch 25/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.2095    \n",
      "Epoch 26/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1971    \n",
      "Epoch 27/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1841    \n",
      "Epoch 28/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1751    \n",
      "Epoch 29/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1646    \n",
      "Epoch 30/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1530    \n",
      "Epoch 31/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1456    \n",
      "Epoch 32/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1373    \n",
      "Epoch 33/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1265    \n",
      "Epoch 34/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1198    \n",
      "Epoch 35/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1108    \n",
      "Epoch 36/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.1051    \n",
      "Epoch 37/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.0979    \n",
      "Epoch 38/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.0930    \n",
      "Epoch 39/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.0859    \n",
      "Epoch 40/40\n",
      "217687/217687 [==============================] - 39s - loss: 2.0791    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32010c36d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.fit(X, y, batch_size=64, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明月落叶下，玉关塞垣月。风声向北游，寒催急春芳。\n",
      "悠然知我德惭不，万行犹在昭享诚。玉门前歌欲亲哀，天白山路遥行路。\n",
      "长河边思君不行，万重轩行未安得。玉关塞天白日月，玉门前鸟飞花似。\n"
     ]
    }
   ],
   "source": [
    "print(gen_poetry(gru, '明月'))\n",
    "print(gen_poetry(gru, '悠然', rows=4, cols=7))\n",
    "print(gen_poetry(gru, '长河', rows=4, cols=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru.save('gru_poetry.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
